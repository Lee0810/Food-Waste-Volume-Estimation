{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1.  Check GPU is ready?",
   "id": "6f9d8526e6581ba4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T13:26:30.383718Z",
     "start_time": "2025-12-26T13:26:23.719273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
   ],
   "id": "6b10dd0ef86a8d28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device Name: NVIDIA GeForce RTX 2050\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Train Model YOLOv8-cls (without neck module)",
   "id": "17b0576d9c3c1e9f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Category 1: Base Model (YOLOv8-cls without neck)",
   "id": "6999148aac1127f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T07:23:55.398428Z",
     "start_time": "2025-11-12T07:23:43.339946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#from ultralytics import YOLO\n",
    "#model = YOLO(\"yolov8n-cls.pt\").model\n",
    "#model.info()"
   ],
   "id": "afc8a12472cda53b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-cls summary: 99 layers, 2,719,288 parameters, 0 gradients, 4.4 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99, 2719288, 0, 4.383948800000001)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T13:33:43.108008Z",
     "start_time": "2025-12-26T13:33:43.037180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "ROOT = r\"C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo\"\n",
    "\n",
    "model = YOLO(r\"C:\\Users\\User\\PycharmProjects\\PythonProject\\.venv39\\Lib\\site-packages\\ultralytics\\cfg\\models\\v8\\yolov8-cls.yaml\")\n"
   ],
   "id": "1ea13393e57d0ff1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING no model scale passed. Assuming scale='n'.\n",
      "YOLOv8-cls summary: 56 layers, 1,567,669 parameters, 1,567,669 gradients, 3.5 GFLOPs\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T13:33:43.800634Z",
     "start_time": "2025-12-26T13:33:43.785636Z"
    }
   },
   "cell_type": "code",
   "source": "print(model.model)",
   "id": "2fc890950b3df8d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (2): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (4): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (6): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (8): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): Classify(\n",
      "      (conv): Conv(\n",
      "        (conv): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (drop): Dropout(p=0.0, inplace=True)\n",
      "      (linear): Linear(in_features=1280, out_features=101, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T19:22:24.881520Z",
     "start_time": "2025-12-26T13:37:44.180542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ROOT = r\"C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\"\n",
    "\n",
    "model.train(\n",
    "    data=ROOT,          # ✅ point to the folder, not a YAML\n",
    "    epochs=30,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    device=0,\n",
    "    workers=2,          # Windows-friendly\n",
    "    project=ROOT,\n",
    "    name=\"runs_model\"\n",
    ")\n",
    "\n",
    "print(\"\\nTraining YOLOv8 without neck is complete.\")\n"
   ],
   "id": "fb1f821e8a21af6c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.241 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\Users\\User\\PycharmProjects\\PythonProject\\.venv39\\Lib\\site-packages\\ultralytics\\cfg\\models\\v8\\yolov8-cls.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=runs_model, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_model, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n",
      "Overriding model.yaml nc=7 with nc=101\n",
      "WARNING no model scale passed. Assuming scale='n'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    459621  ultralytics.nn.modules.head.Classify         [256, 101]                    \n",
      "YOLOv8-cls summary: 56 layers, 1,567,669 parameters, 1,567,669 gradients, 3.5 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 0.40.1 ms, read: 54.26.9 MB/s, size: 48.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 75750 images, 0 corrupt: 100%|██████████| 75750/75750 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access  (ping: 0.40.4 ms, read: 40.321.5 MB/s, size: 37.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... 25250 images, 0 corrupt: 100%|██████████| 25250/25250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_model\u001B[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30     0.365G      4.502          6        224: 100%|██████████| 2368/2368 [06:29<00:00,  6.08it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:20<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0703      0.236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30     0.432G      4.052          6        224: 100%|██████████| 2368/2368 [06:06<00:00,  6.46it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:53<00:00,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.155      0.399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30     0.432G        3.7          6        224: 100%|██████████| 2368/2368 [07:42<00:00,  5.11it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:42<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.258      0.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30     0.432G      3.365          6        224: 100%|██████████| 2368/2368 [07:07<00:00,  5.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:36<00:00,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.379      0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30     0.432G      3.053          6        224: 100%|██████████| 2368/2368 [06:49<00:00,  5.78it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:36<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.455      0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30     0.432G      2.818          6        224: 100%|██████████| 2368/2368 [06:49<00:00,  5.78it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:32<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.511      0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30     0.432G      2.632          6        224: 100%|██████████| 2368/2368 [07:08<00:00,  5.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:56<00:00,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.552       0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30     0.432G      2.485          6        224: 100%|██████████| 2368/2368 [07:08<00:00,  5.52it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:52<00:00,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.585      0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30     0.432G      2.376          6        224: 100%|██████████| 2368/2368 [10:35<00:00,  3.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:30<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.609      0.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30     0.432G      2.276          6        224: 100%|██████████| 2368/2368 [09:57<00:00,  3.96it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:50<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.625      0.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30     0.432G      2.193          6        224: 100%|██████████| 2368/2368 [11:05<00:00,  3.56it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:27<00:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.64      0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30     0.432G      2.117          6        224: 100%|██████████| 2368/2368 [10:21<00:00,  3.81it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:36<00:00,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.652       0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30     0.432G      2.053          6        224: 100%|██████████| 2368/2368 [11:11<00:00,  3.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:35<00:00,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.659      0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30     0.432G      1.995          6        224: 100%|██████████| 2368/2368 [11:11<00:00,  3.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:34<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.666      0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30     0.432G       1.94          6        224: 100%|██████████| 2368/2368 [11:21<00:00,  3.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:40<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.672      0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30     0.432G      1.886          6        224: 100%|██████████| 2368/2368 [10:41<00:00,  3.69it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:37<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.676      0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30     0.432G      1.834          6        224: 100%|██████████| 2368/2368 [10:55<00:00,  3.61it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:33<00:00,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.68      0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30     0.432G      1.792          6        224: 100%|██████████| 2368/2368 [10:33<00:00,  3.74it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:41<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.684      0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30     0.432G      1.747          6        224: 100%|██████████| 2368/2368 [10:44<00:00,  3.68it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:27<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.688        0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30     0.432G      1.698          6        224: 100%|██████████| 2368/2368 [10:40<00:00,  3.70it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:31<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.69      0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30     0.432G      1.653          6        224: 100%|██████████| 2368/2368 [10:39<00:00,  3.70it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:55<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.695      0.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30     0.432G      1.615          6        224: 100%|██████████| 2368/2368 [10:14<00:00,  3.86it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:22<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.699      0.907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30     0.432G      1.567          6        224: 100%|██████████| 2368/2368 [11:04<00:00,  3.56it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:50<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.704      0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30     0.432G      1.523          6        224: 100%|██████████| 2368/2368 [12:22<00:00,  3.19it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:43<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.708      0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30     0.432G      1.481          6        224: 100%|██████████| 2368/2368 [12:14<00:00,  3.23it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:35<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.712      0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30     0.432G      1.436          6        224: 100%|██████████| 2368/2368 [07:17<00:00,  5.41it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:35<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.717      0.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30     0.432G      1.388          6        224: 100%|██████████| 2368/2368 [06:15<00:00,  6.31it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:22<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.721      0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30     0.432G      1.339          6        224: 100%|██████████| 2368/2368 [06:10<00:00,  6.39it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:52<00:00,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.725       0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30     0.432G      1.295          6        224: 100%|██████████| 2368/2368 [07:06<00:00,  5.56it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:37<00:00,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.73      0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30     0.432G      1.252          6        224: 100%|██████████| 2368/2368 [07:24<00:00,  5.33it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:39<00:00,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.734      0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 5.710 hours.\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_model\\weights\\last.pt, 3.2MB\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_model\\weights\\best.pt, 3.2MB\n",
      "\n",
      "Validating C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_model\\weights\\best.pt...\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "YOLOv8-cls summary (fused): 30 layers, 1,564,261 parameters, 0 gradients, 3.4 GFLOPs\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:31<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.734      0.923\n",
      "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_model\u001B[0m\n",
      "\n",
      "Training YOLOv8 without neck is complete.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2e30d1f889450b41"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Resume Category 1: Base Model (YOLOv8-cls without neck)",
   "id": "cba51cd24d4b085d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T16:49:19.260778Z",
     "start_time": "2025-11-12T14:34:48.634344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(r\"C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\Result_CLS_No_Neck\\runs\\weights\\last.pt\")\n",
    "\n",
    "model.train(\n",
    "    resume=True,  # ✅ resume from where it stopped\n",
    "    device=0\n",
    ")\n"
   ],
   "id": "4ea30d70e146158f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.227 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.34  Python-3.12.6 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0mtask=classify, mode=train, model=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs2\\weights\\last.pt, data=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, epochs=50, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=-1, cache=False, device=0, workers=2, project=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, name=runs2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs2\\weights\\last.pt, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs2\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs2', view at http://localhost:6006/\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    459621  ultralytics.nn.modules.head.Classify         [256, 101]                    \n",
      "YOLOv8n-cls summary: 99 layers, 1,567,669 parameters, 1,567,669 gradients, 3.5 GFLOPs\n",
      "Transferred 158/158 items from pretrained weights\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 75750 images, 0 corrupt: 100%|██████████| 75750/75750 [00:00<?, ?it/s]\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... 25250 images, 0 corrupt: 100%|██████████| 25250/25250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Resuming training C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs2\\weights\\last.pt from epoch 40 to 50 total epochs\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added \n",
      "Image sizes 224 train, 224 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs2\u001B[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50     0.384G     0.7628          6        224: 100%|██████████| 2368/2368 [09:05<00:00,  4.34it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:21<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.822       0.96\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50     0.407G      0.759          6        224: 100%|██████████| 2368/2368 [08:21<00:00,  4.72it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:47<00:00,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.823       0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50     0.386G     0.7385          6        224: 100%|██████████| 2368/2368 [07:39<00:00,  5.16it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:46<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.824       0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50     0.386G     0.7169          6        224: 100%|██████████| 2368/2368 [06:45<00:00,  5.84it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:37<00:00,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.825      0.961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50     0.386G     0.6876          6        224: 100%|██████████| 2368/2368 [11:20<00:00,  3.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:23<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.826      0.961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50     0.386G     0.6672          6        224: 100%|██████████| 2368/2368 [11:19<00:00,  3.49it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:20<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.826      0.961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50     0.386G     0.6468          6        224: 100%|██████████| 2368/2368 [10:27<00:00,  3.78it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:31<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.826      0.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50     0.386G     0.6196          6        224: 100%|██████████| 2368/2368 [10:00<00:00,  3.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:54<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.826      0.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50     0.386G     0.5868          6        224: 100%|██████████| 2368/2368 [09:43<00:00,  4.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:37<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.826      0.961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50     0.386G     0.5643          6        224: 100%|██████████| 2368/2368 [11:51<00:00,  3.33it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:41<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.826      0.961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50     0.386G     0.5396          6        224: 100%|██████████| 2368/2368 [10:03<00:00,  3.92it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:13<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.826      0.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "11 epochs completed in 2.197 hours.\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs2\\weights\\last.pt, 3.2MB\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs2\\weights\\best.pt, 3.2MB\n",
      "\n",
      "Validating C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs2\\weights\\best.pt...\n",
      "Ultralytics 8.3.34  Python-3.12.6 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1,564,261 parameters, 0 gradients, 3.4 GFLOPs\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:29<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.826      0.961\n",
      "Speed: 0.2ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs2\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002EBE8B1BF80>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.893900990486145\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.8264158368110657, 'metrics/accuracy_top5': 0.9613861441612244, 'fitness': 0.893900990486145}\n",
       "save_dir: WindowsPath('C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo/runs2')\n",
       "speed: {'preprocess': 0.15342821933255335, 'inference': 0.5315039323108031, 'loss': 1.2246688993850557e-05, 'postprocess': 0.00042723665143003557}\n",
       "task: 'classify'\n",
       "top1: 0.8264158368110657\n",
       "top5: 0.9613861441612244"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T06:56:48.380365Z",
     "start_time": "2025-12-26T06:56:47.402749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print training result of the Classify Task (Category 1 Base Model)\n",
    "import pandas as pd\n",
    "\n",
    "# Load your YOLO training results file\n",
    "result_CT = pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\Result_CLS_No_Neck\\runs\\results.csv\")\n",
    "\n",
    "# Show all epochs\n",
    "result_CT.tail(24)\n"
   ],
   "id": "78965bc91abf0e85",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    epoch       time  train/loss  metrics/accuracy_top1  \\\n",
       "26     27  17509.500     1.10040                0.80974   \n",
       "27     28  18092.300     1.06988                0.81176   \n",
       "28     29  18673.100     1.05579                0.81267   \n",
       "29     30  19260.500     1.03710                0.81386   \n",
       "30     31  19846.000     1.01391                0.81386   \n",
       "31     32  20426.800     0.98953                0.81489   \n",
       "32     33  21037.300     0.97099                0.81592   \n",
       "33     34  21627.400     0.94513                0.81711   \n",
       "34     35  22223.400     0.92663                0.81850   \n",
       "35     36  22856.600     0.89022                0.81905   \n",
       "36     37  23513.700     0.86764                0.81956   \n",
       "37     38  24265.700     0.84841                0.82059   \n",
       "38     39  25169.800     0.81985                0.82079   \n",
       "39     40    688.551     0.76279                0.82166   \n",
       "40     41   1343.170     0.75903                0.82281   \n",
       "41     42   1909.310     0.73852                0.82376   \n",
       "42     43   2413.310     0.71687                0.82523   \n",
       "43     44   3238.480     0.68762                0.82550   \n",
       "44     45   4059.560     0.66723                0.82598   \n",
       "45     46   4838.800     0.64684                0.82630   \n",
       "46     47   5555.310     0.61961                0.82650   \n",
       "47     48   6296.860     0.58680                0.82586   \n",
       "48     49   7170.380     0.56429                0.82618   \n",
       "49     50   7908.310     0.53959                0.82622   \n",
       "\n",
       "    metrics/accuracy_top5  val/loss    lr/pg0    lr/pg1    lr/pg2  \n",
       "26                0.95529   3.88503  0.004852  0.004852  0.004852  \n",
       "27                0.95572   3.88389  0.004654  0.004654  0.004654  \n",
       "28                0.95604   3.88285  0.004456  0.004456  0.004456  \n",
       "29                0.95675   3.88163  0.004258  0.004258  0.004258  \n",
       "30                0.95671   3.88039  0.004060  0.004060  0.004060  \n",
       "31                0.95679   3.87938  0.003862  0.003862  0.003862  \n",
       "32                0.95750   3.87791  0.003664  0.003664  0.003664  \n",
       "33                0.95838   3.87659  0.003466  0.003466  0.003466  \n",
       "34                0.95838   3.87556  0.003268  0.003268  0.003268  \n",
       "35                0.95917   3.87429  0.003070  0.003070  0.003070  \n",
       "36                0.95937   3.87290  0.002872  0.002872  0.002872  \n",
       "37                0.95921   3.87137  0.002674  0.002674  0.002674  \n",
       "38                0.95960   3.87019  0.002476  0.002476  0.002476  \n",
       "39                0.95996   3.86773  0.002278  0.002278  0.002278  \n",
       "40                0.96000   3.86584  0.002080  0.002080  0.002080  \n",
       "41                0.96028   3.86409  0.001882  0.001882  0.001882  \n",
       "42                0.96059   3.86268  0.001684  0.001684  0.001684  \n",
       "43                0.96063   3.86145  0.001486  0.001486  0.001486  \n",
       "44                0.96083   3.86030  0.001288  0.001288  0.001288  \n",
       "45                0.96154   3.85971  0.001090  0.001090  0.001090  \n",
       "46                0.96150   3.85882  0.000892  0.000892  0.000892  \n",
       "47                0.96143   3.85811  0.000694  0.000694  0.000694  \n",
       "48                0.96131   3.85742  0.000496  0.000496  0.000496  \n",
       "49                0.96166   3.85686  0.000298  0.000298  0.000298  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>time</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>metrics/accuracy_top1</th>\n",
       "      <th>metrics/accuracy_top5</th>\n",
       "      <th>val/loss</th>\n",
       "      <th>lr/pg0</th>\n",
       "      <th>lr/pg1</th>\n",
       "      <th>lr/pg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>17509.500</td>\n",
       "      <td>1.10040</td>\n",
       "      <td>0.80974</td>\n",
       "      <td>0.95529</td>\n",
       "      <td>3.88503</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.004852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>18092.300</td>\n",
       "      <td>1.06988</td>\n",
       "      <td>0.81176</td>\n",
       "      <td>0.95572</td>\n",
       "      <td>3.88389</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.004654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>18673.100</td>\n",
       "      <td>1.05579</td>\n",
       "      <td>0.81267</td>\n",
       "      <td>0.95604</td>\n",
       "      <td>3.88285</td>\n",
       "      <td>0.004456</td>\n",
       "      <td>0.004456</td>\n",
       "      <td>0.004456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>19260.500</td>\n",
       "      <td>1.03710</td>\n",
       "      <td>0.81386</td>\n",
       "      <td>0.95675</td>\n",
       "      <td>3.88163</td>\n",
       "      <td>0.004258</td>\n",
       "      <td>0.004258</td>\n",
       "      <td>0.004258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>19846.000</td>\n",
       "      <td>1.01391</td>\n",
       "      <td>0.81386</td>\n",
       "      <td>0.95671</td>\n",
       "      <td>3.88039</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.004060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>20426.800</td>\n",
       "      <td>0.98953</td>\n",
       "      <td>0.81489</td>\n",
       "      <td>0.95679</td>\n",
       "      <td>3.87938</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.003862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>21037.300</td>\n",
       "      <td>0.97099</td>\n",
       "      <td>0.81592</td>\n",
       "      <td>0.95750</td>\n",
       "      <td>3.87791</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>0.003664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>21627.400</td>\n",
       "      <td>0.94513</td>\n",
       "      <td>0.81711</td>\n",
       "      <td>0.95838</td>\n",
       "      <td>3.87659</td>\n",
       "      <td>0.003466</td>\n",
       "      <td>0.003466</td>\n",
       "      <td>0.003466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>22223.400</td>\n",
       "      <td>0.92663</td>\n",
       "      <td>0.81850</td>\n",
       "      <td>0.95838</td>\n",
       "      <td>3.87556</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.003268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>22856.600</td>\n",
       "      <td>0.89022</td>\n",
       "      <td>0.81905</td>\n",
       "      <td>0.95917</td>\n",
       "      <td>3.87429</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>0.003070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>23513.700</td>\n",
       "      <td>0.86764</td>\n",
       "      <td>0.81956</td>\n",
       "      <td>0.95937</td>\n",
       "      <td>3.87290</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.002872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>24265.700</td>\n",
       "      <td>0.84841</td>\n",
       "      <td>0.82059</td>\n",
       "      <td>0.95921</td>\n",
       "      <td>3.87137</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.002674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>25169.800</td>\n",
       "      <td>0.81985</td>\n",
       "      <td>0.82079</td>\n",
       "      <td>0.95960</td>\n",
       "      <td>3.87019</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.002476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>688.551</td>\n",
       "      <td>0.76279</td>\n",
       "      <td>0.82166</td>\n",
       "      <td>0.95996</td>\n",
       "      <td>3.86773</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>0.002278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>1343.170</td>\n",
       "      <td>0.75903</td>\n",
       "      <td>0.82281</td>\n",
       "      <td>0.96000</td>\n",
       "      <td>3.86584</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.002080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>1909.310</td>\n",
       "      <td>0.73852</td>\n",
       "      <td>0.82376</td>\n",
       "      <td>0.96028</td>\n",
       "      <td>3.86409</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.001882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>2413.310</td>\n",
       "      <td>0.71687</td>\n",
       "      <td>0.82523</td>\n",
       "      <td>0.96059</td>\n",
       "      <td>3.86268</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>0.001684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>3238.480</td>\n",
       "      <td>0.68762</td>\n",
       "      <td>0.82550</td>\n",
       "      <td>0.96063</td>\n",
       "      <td>3.86145</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.001486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>4059.560</td>\n",
       "      <td>0.66723</td>\n",
       "      <td>0.82598</td>\n",
       "      <td>0.96083</td>\n",
       "      <td>3.86030</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.001288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>4838.800</td>\n",
       "      <td>0.64684</td>\n",
       "      <td>0.82630</td>\n",
       "      <td>0.96154</td>\n",
       "      <td>3.85971</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.001090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>5555.310</td>\n",
       "      <td>0.61961</td>\n",
       "      <td>0.82650</td>\n",
       "      <td>0.96150</td>\n",
       "      <td>3.85882</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.000892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>6296.860</td>\n",
       "      <td>0.58680</td>\n",
       "      <td>0.82586</td>\n",
       "      <td>0.96143</td>\n",
       "      <td>3.85811</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>7170.380</td>\n",
       "      <td>0.56429</td>\n",
       "      <td>0.82618</td>\n",
       "      <td>0.96131</td>\n",
       "      <td>3.85742</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>7908.310</td>\n",
       "      <td>0.53959</td>\n",
       "      <td>0.82622</td>\n",
       "      <td>0.96166</td>\n",
       "      <td>3.85686</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Train Model YOLOv8-cls (with neck module)",
   "id": "94739b0c5f0b7b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Category 2: Base Model (YOLOv8-cls with neck)",
   "id": "9a5872538aab4726"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T13:43:46.644473Z",
     "start_time": "2025-12-14T13:43:46.437401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "ROOT = r\"C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo\"\n",
    "\n",
    "# Use your modified yolov8n-cls.yaml (with Neck)\n",
    "model_neck = YOLO(r\"C:/Users/User/PycharmProjects/PythonProject/.venv39/Lib/site-packages/ultralytics/cfg/models/v8/yolov8n-cls.yaml\")\n"
   ],
   "id": "1d3a840a8e39222f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-cls summary: 103 layers, 2,719,157 parameters, 2,719,157 gradients, 5.6 GFLOPs\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T13:43:48.286143Z",
     "start_time": "2025-12-14T13:43:48.274523Z"
    }
   },
   "cell_type": "code",
   "source": "print(model_neck.model)",
   "id": "90f2bfee1d07ebde",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (2): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (4): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (6): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (8): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): SPPF(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (10): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (11): Concat()\n",
      "    (12): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (14): Concat()\n",
      "    (15): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (17): Concat()\n",
      "    (18): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (20): Concat()\n",
      "    (21): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (22): Classify(\n",
      "      (conv): Conv(\n",
      "        (conv): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (drop): Dropout(p=0.0, inplace=True)\n",
      "      (linear): Linear(in_features=1280, out_features=101, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-14T13:44:01.051204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model_neck.train(\n",
    "    data=ROOT,          # ✅ point to the folder, not a YAML\n",
    "    epochs=50,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    device=0,\n",
    "    workers=2,          # Windows-friendly\n",
    "    project=ROOT,\n",
    "    name=\"runs_neck\"\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Yolov8 -cls with neck is complete.\")\n"
   ],
   "id": "18e2e5e89e5e31ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.237 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:/Users/User/PycharmProjects/PythonProject/.venv39/Lib/site-packages/ultralytics/cfg/models/v8/yolov8n-cls.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=runs_neck, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_neck, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22                  -1  1    459621  ultralytics.nn.modules.head.Classify         [256, 101]                    \n",
      "YOLOv8n-cls summary: 103 layers, 2,719,157 parameters, 2,719,157 gradients, 5.6 GFLOPs\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 0.10.0 ms, read: 62.635.0 MB/s, size: 48.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 33871 images, 0 corrupt:  45%|████▍     | 33871/75750 [00:24<00:27, 1542.97it/s]C:\\Users\\User\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\PIL\\TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 75750 images, 0 corrupt: 100%|██████████| 75750/75750 [00:52<00:00, 1453.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train.cache\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T22:26:21.198204Z",
     "start_time": "2025-12-14T20:12:49.833286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model_neck = YOLO(r\"C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo/runs_neck/weights/last.pt\")\n",
    "\n",
    "model_neck.train(\n",
    "    resume=True,  # ✅ resume from where it stopped\n",
    "    device=0\n",
    ")\n"
   ],
   "id": "4f17cb2887fe6246",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.237 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_neck\\weights\\last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=runs_neck, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, rect=False, resume=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_neck\\weights\\last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_neck, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22                  -1  1    459621  ultralytics.nn.modules.head.Classify         [256, 101]                    \n",
      "YOLOv8n-cls summary: 103 layers, 2,719,157 parameters, 2,719,157 gradients, 5.6 GFLOPs\n",
      "Transferred 278/278 items from pretrained weights\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 0.40.1 ms, read: 71.410.7 MB/s, size: 48.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 75750 images, 0 corrupt: 100%|██████████| 75750/75750 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access  (ping: 0.40.4 ms, read: 36.813.7 MB/s, size: 37.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... 25250 images, 0 corrupt: 100%|██████████| 25250/25250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01, momentum=0.9) with parameter groups 46 weight(decay=0.0), 47 weight(decay=0.0005), 47 bias(decay=0.0)\n",
      "Resuming training C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_neck\\weights\\last.pt from epoch 38 to 50 total epochs\n",
      "Image sizes 224 train, 224 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_neck\u001B[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50     0.492G      1.358          6        224: 100%|██████████| 2368/2368 [10:19<00:00,  3.82it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:04<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.745      0.929\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50     0.555G      1.344          6        224: 100%|██████████| 2368/2368 [07:51<00:00,  5.02it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:51<00:00,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.749      0.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50     0.555G      1.312          6        224: 100%|██████████| 2368/2368 [08:03<00:00,  4.89it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:52<00:00,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.753      0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50     0.555G      1.282          6        224: 100%|██████████| 2368/2368 [07:46<00:00,  5.07it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:50<00:00,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.756      0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50     0.557G      1.254          6        224: 100%|██████████| 2368/2368 [07:47<00:00,  5.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:57<00:00,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.759      0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50     0.557G       1.22          6        224: 100%|██████████| 2368/2368 [07:46<00:00,  5.07it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:52<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.761      0.936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50     0.557G      1.186          6        224: 100%|██████████| 2368/2368 [07:56<00:00,  4.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:53<00:00,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.763      0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50     0.557G      1.147          6        224: 100%|██████████| 2368/2368 [07:48<00:00,  5.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:50<00:00,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.766      0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50     0.557G      1.113          6        224: 100%|██████████| 2368/2368 [07:53<00:00,  5.00it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:54<00:00,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.769      0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50     0.557G      1.078          6        224: 100%|██████████| 2368/2368 [07:47<00:00,  5.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:54<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.771       0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50     0.557G      1.035          6        224: 100%|██████████| 2368/2368 [07:55<00:00,  4.98it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:51<00:00,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.773      0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50     0.557G     0.9982          6        224: 100%|██████████| 2368/2368 [07:56<00:00,  4.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:54<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.775      0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50     0.557G     0.9647          6        224: 100%|██████████| 2368/2368 [08:01<00:00,  4.92it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:56<00:00,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.777      0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "13 epochs completed in 2.169 hours.\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_neck\\weights\\last.pt, 5.6MB\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_neck\\weights\\best.pt, 5.6MB\n",
      "\n",
      "Validating C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_neck\\weights\\best.pt...\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "YOLOv8n-cls summary (fused): 57 layers, 2,713,445 parameters, 0 gradients, 5.5 GFLOPs\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:27<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.777      0.942\n",
      "Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_neck\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x00000215E8811DF0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.8597227931022644\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.7774257659912109, 'metrics/accuracy_top5': 0.9420198202133179, 'fitness': 0.8597227931022644}\n",
       "save_dir: WindowsPath('C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo/runs_neck')\n",
       "speed: {'preprocess': 0.13999834455437912, 'inference': 0.540131160396125, 'loss': 0.0003027009899759121, 'postprocess': 0.0006436316832357736}\n",
       "task: 'classify'\n",
       "top1: 0.7774257659912109\n",
       "top5: 0.9420198202133179"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f56a1102eb55ae9f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
