{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1.  Check GPU is ready?",
   "id": "70fdad0b8d9f2821"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T07:18:27.770061Z",
     "start_time": "2025-12-26T07:18:22.886443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
   ],
   "id": "6f9e72e4159ebd6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device Name: NVIDIA GeForce RTX 2050\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Train Model YOLOv8-cls (without neck module)",
   "id": "38a95799be60f9a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Category 1: Base Model (YOLOv8-cls without neck) + SPPF",
   "id": "998d3409d8d72bae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T06:52:43.513991Z",
     "start_time": "2025-12-07T06:52:35.394065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "ROOT = r\"C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo\"\n",
    "\n",
    "# Use your modified yolov8n-cls.yaml (with SPPF)\n",
    "modelSPPF = YOLO(r\"C:/Users/User/PycharmProjects/PythonProject/.venv39/Lib/site-packages/ultralytics/cfg/models/v8/yolov8n-cls.yaml\")"
   ],
   "id": "291d6c79a5e684f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-cls summary: 61 layers, 1,732,277 parameters, 1,732,277 gradients, 3.6 GFLOPs\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T06:52:56.142404Z",
     "start_time": "2025-12-07T06:52:56.122435Z"
    }
   },
   "cell_type": "code",
   "source": "print(modelSPPF.model)",
   "id": "9d32ce4f14d3c01e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (2): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (4): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (6): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (8): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): SPPF(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (10): Classify(\n",
      "      (conv): Conv(\n",
      "        (conv): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (drop): Dropout(p=0.0, inplace=True)\n",
      "      (linear): Linear(in_features=1280, out_features=101, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-07T06:57:59.668640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "modelSPPF.train(\n",
    "    data=ROOT,\n",
    "    epochs=30,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    device=0,\n",
    "    workers=2,\n",
    "    project=ROOT,\n",
    "    name=\"runs_SPPF\",\n",
    ")\n",
    "print(\"\\nSPPF model training is complete.\")\n"
   ],
   "id": "1013adc70f878fbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.235 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:/Users/User/PycharmProjects/PythonProject/.venv39/Lib/site-packages/ultralytics/cfg/models/v8/yolov8n-cls.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=runs_SPPF, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_SPPF, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    459621  ultralytics.nn.modules.head.Classify         [256, 101]                    \n",
      "YOLOv8n-cls summary: 61 layers, 1,732,277 parameters, 1,732,277 gradients, 3.6 GFLOPs\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 29.210.6 ms, read: 4.93.5 MB/s, size: 48.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 33630 images, 0 corrupt:  44%|████▍     | 33630/75750 [02:04<14:42, 47.71it/s]  C:\\Users\\User\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\PIL\\TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 41604 images, 0 corrupt:  55%|█████▍    | 41604/75750 [03:06<01:52, 302.54it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Category 1: Base Model (YOLOv8-cls without neck) + Spatial",
   "id": "3839324a1970dbc7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:51:49.675598Z",
     "start_time": "2025-12-07T16:51:48.760199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "ROOT = r\"C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo\"\n",
    "\n",
    "# Use your modified yolov8n-cls.yaml (with SA Attention)\n",
    "modelSA = YOLO(r\"C:/Users/User/PycharmProjects/PythonProject/.venv39/Lib/site-packages/ultralytics/cfg/models/v8/yolov8n-cls.yaml\")"
   ],
   "id": "6e2552f6a91fcb1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-cls summary: 58 layers, 1,567,767 parameters, 1,567,767 gradients, 3.5 GFLOPs\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:51:58.987029Z",
     "start_time": "2025-12-07T16:51:58.965391Z"
    }
   },
   "cell_type": "code",
   "source": "print(modelSA.model)",
   "id": "96071f3371755a5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (2): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (4): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (6): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (8): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): SpatialAttention(\n",
      "      (cv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (10): Classify(\n",
      "      (conv): Conv(\n",
      "        (conv): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (drop): Dropout(p=0.0, inplace=True)\n",
      "      (linear): Linear(in_features=1280, out_features=101, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T21:29:08.089986Z",
     "start_time": "2025-12-07T16:53:26.409697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "modelSA.train(\n",
    "    data=ROOT,\n",
    "    epochs=30,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    device=0,\n",
    "    workers=2,\n",
    "    project=ROOT,\n",
    "    name=\"runs_SA\",\n",
    ")\n",
    "print(\"\\nSA model training is complete.\")\n"
   ],
   "id": "f12e0b40c594181d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.235 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:/Users/User/PycharmProjects/PythonProject/.venv39/Lib/site-packages/ultralytics/cfg/models/v8/yolov8n-cls.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=runs_SA, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_SA, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1        98  ultralytics.nn.modules.conv.SpatialAttention [7]                           \n",
      " 10                  -1  1    459621  ultralytics.nn.modules.head.Classify         [256, 101]                    \n",
      "YOLOv8n-cls summary: 58 layers, 1,567,767 parameters, 1,567,767 gradients, 3.5 GFLOPs\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 0.60.2 ms, read: 28.68.7 MB/s, size: 48.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 33907 images, 0 corrupt:  45%|████▍     | 33907/75750 [00:18<00:38, 1098.42it/s]C:\\Users\\User\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\PIL\\TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 75750 images, 0 corrupt: 100%|██████████| 75750/75750 [00:53<00:00, 1413.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train.cache\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access  (ping: 0.30.2 ms, read: 43.211.0 MB/s, size: 37.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val...:   0%|          | 0/25250 [00:00<?, ?it/s]C:\\Users\\User\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\PIL\\TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... 25250 images, 0 corrupt: 100%|██████████| 25250/25250 [00:13<00:00, 1930.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val.cache\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01, momentum=0.9) with parameter groups 26 weight(decay=0.0), 28 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_SA\u001B[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30      0.41G      4.492          6        224: 100%|██████████| 2368/2368 [08:40<00:00,  4.55it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:47<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0693      0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30     0.477G       4.06          6        224: 100%|██████████| 2368/2368 [07:08<00:00,  5.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:44<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.159      0.408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30     0.477G      3.711          6        224: 100%|██████████| 2368/2368 [07:01<00:00,  5.61it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:38<00:00,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.258      0.541\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       4/30     0.477G       3.36          6        224: 100%|██████████| 2368/2368 [07:07<00:00,  5.54it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:40<00:00,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.38      0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30     0.477G      3.036          6        224: 100%|██████████| 2368/2368 [07:13<00:00,  5.46it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:38<00:00,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.456      0.743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30     0.477G      2.793          6        224: 100%|██████████| 2368/2368 [07:02<00:00,  5.60it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:39<00:00,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.514       0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30     0.477G       2.61          6        224: 100%|██████████| 2368/2368 [06:53<00:00,  5.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:37<00:00,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.557      0.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30     0.477G      2.468          6        224: 100%|██████████| 2368/2368 [06:55<00:00,  5.70it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:36<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.585      0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30     0.477G      2.356          6        224: 100%|██████████| 2368/2368 [06:56<00:00,  5.69it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:41<00:00,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.608      0.857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30     0.477G      2.258          6        224: 100%|██████████| 2368/2368 [07:07<00:00,  5.54it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:38<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.628      0.868\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      11/30     0.477G      2.178          6        224: 100%|██████████| 2368/2368 [06:49<00:00,  5.78it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:40<00:00,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.638      0.876\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      12/30     0.477G      2.107          6        224: 100%|██████████| 2368/2368 [07:05<00:00,  5.57it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:37<00:00,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.647       0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30     0.477G      2.041          6        224: 100%|██████████| 2368/2368 [07:04<00:00,  5.57it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:43<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.655      0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30     0.477G      1.985          6        224: 100%|██████████| 2368/2368 [07:11<00:00,  5.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:45<00:00,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.661      0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30     0.477G      1.931          6        224: 100%|██████████| 2368/2368 [07:13<00:00,  5.47it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:42<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.666      0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30     0.477G      1.875          6        224: 100%|██████████| 2368/2368 [06:49<00:00,  5.78it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:41<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.669      0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30     0.477G      1.825          6        224: 100%|██████████| 2368/2368 [07:55<00:00,  4.98it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:45<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.673      0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30     0.477G      1.778          6        224: 100%|██████████| 2368/2368 [07:15<00:00,  5.44it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:43<00:00,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.677      0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30     0.477G      1.734          6        224: 100%|██████████| 2368/2368 [07:10<00:00,  5.50it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:48<00:00,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.681      0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30     0.477G      1.684          6        224: 100%|██████████| 2368/2368 [07:15<00:00,  5.44it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:41<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.685        0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30     0.477G      1.642          6        224: 100%|██████████| 2368/2368 [07:12<00:00,  5.47it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:51<00:00,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.689      0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30     0.477G      1.604          6        224: 100%|██████████| 2368/2368 [07:27<00:00,  5.29it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:41<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.694      0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30     0.477G      1.554          6        224: 100%|██████████| 2368/2368 [07:31<00:00,  5.24it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:42<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.699      0.907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30     0.477G      1.517          6        224: 100%|██████████| 2368/2368 [07:33<00:00,  5.23it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:47<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.703       0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30     0.477G      1.474          6        224: 100%|██████████| 2368/2368 [07:31<00:00,  5.25it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:45<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.709      0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30     0.477G      1.424          6        224: 100%|██████████| 2368/2368 [07:22<00:00,  5.35it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:51<00:00,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.715      0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30     0.477G      1.379          6        224: 100%|██████████| 2368/2368 [07:18<00:00,  5.41it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:52<00:00,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.719      0.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30     0.477G      1.324          6        224: 100%|██████████| 2368/2368 [07:40<00:00,  5.15it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:48<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.723      0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30     0.477G       1.28          6        224: 100%|██████████| 2368/2368 [07:49<00:00,  5.04it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:51<00:00,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.727      0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30     0.477G      1.236          6        224: 100%|██████████| 2368/2368 [07:46<00:00,  5.07it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:52<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.73      0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 4.530 hours.\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_SA\\weights\\last.pt, 3.2MB\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_SA\\weights\\best.pt, 3.2MB\n",
      "\n",
      "Validating C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_SA\\weights\\best.pt...\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "YOLOv8n-cls summary (fused): 32 layers, 1,564,359 parameters, 0 gradients, 3.4 GFLOPs\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:28<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.73      0.923\n",
      "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_SA\u001B[0m\n",
      "\n",
      "SA model training is complete.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Category 1: Base Model (YOLOv8-cls without neck) + Channel",
   "id": "b4b49a5daf7d5691"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T09:06:00.351785Z",
     "start_time": "2025-12-08T09:05:59.834160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "ROOT = r\"C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo\"\n",
    "\n",
    "# Use your modified yolov8n-cls.yaml (with CA Attention)\n",
    "modelCA = YOLO(r\"C:/Users/User/PycharmProjects/PythonProject/.venv39/Lib/site-packages/ultralytics/cfg/models/v8/yolov8n-cls.yaml\")"
   ],
   "id": "185ec873128d45c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-cls summary: 59 layers, 1,633,461 parameters, 1,633,461 gradients, 3.5 GFLOPs\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T09:06:01.413342Z",
     "start_time": "2025-12-08T09:06:01.381775Z"
    }
   },
   "cell_type": "code",
   "source": "print(modelCA.model)",
   "id": "db1f7ee2a7905014",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (2): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (4): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (6): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (8): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): ChannelAttention(\n",
      "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (fc): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (10): Classify(\n",
      "      (conv): Conv(\n",
      "        (conv): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (drop): Dropout(p=0.0, inplace=True)\n",
      "      (linear): Linear(in_features=1280, out_features=101, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T13:45:49.637882Z",
     "start_time": "2025-12-08T09:06:05.704836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "modelCA.train(\n",
    "    data=ROOT,\n",
    "    epochs=30,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    device=0,\n",
    "    workers=2,\n",
    "    project=ROOT,\n",
    "    name=\"runs_CA\",\n",
    ")\n",
    "print(\"\\nCA model training is complete.\")\n"
   ],
   "id": "8841dac293b5c427",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.235 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:/Users/User/PycharmProjects/PythonProject/.venv39/Lib/site-packages/ultralytics/cfg/models/v8/yolov8n-cls.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=runs_CA2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_CA2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1     65792  ultralytics.nn.modules.conv.ChannelAttention [256]                         \n",
      " 10                  -1  1    459621  ultralytics.nn.modules.head.Classify         [256, 101]                    \n",
      "YOLOv8n-cls summary: 59 layers, 1,633,461 parameters, 1,633,461 gradients, 3.5 GFLOPs\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 0.50.3 ms, read: 36.88.3 MB/s, size: 48.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 75750 images, 0 corrupt: 100%|██████████| 75750/75750 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access  (ping: 0.20.2 ms, read: 60.112.8 MB/s, size: 37.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... 25250 images, 0 corrupt: 100%|██████████| 25250/25250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01, momentum=0.9) with parameter groups 26 weight(decay=0.0), 28 weight(decay=0.0005), 28 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_CA2\u001B[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30     0.627G      4.486          6        224: 100%|██████████| 2368/2368 [07:59<00:00,  4.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:45<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0688      0.231\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30     0.691G      4.042          6        224: 100%|██████████| 2368/2368 [07:21<00:00,  5.37it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:42<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.161      0.409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30     0.693G      3.684          6        224: 100%|██████████| 2368/2368 [07:12<00:00,  5.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:42<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.267      0.556\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       4/30     0.693G      3.317          6        224: 100%|██████████| 2368/2368 [07:19<00:00,  5.38it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:41<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.394      0.687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30     0.693G      2.988          6        224: 100%|██████████| 2368/2368 [07:24<00:00,  5.33it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:42<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.471      0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30     0.693G      2.749          6        224: 100%|██████████| 2368/2368 [07:09<00:00,  5.52it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:38<00:00,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.525      0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30     0.693G      2.566          6        224: 100%|██████████| 2368/2368 [07:11<00:00,  5.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:39<00:00,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.567      0.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30     0.693G      2.417          6        224: 100%|██████████| 2368/2368 [07:04<00:00,  5.58it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:42<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.597       0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30     0.693G      2.314          6        224: 100%|██████████| 2368/2368 [07:00<00:00,  5.64it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:42<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.619      0.863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30     0.693G      2.211          6        224: 100%|██████████| 2368/2368 [07:06<00:00,  5.55it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:46<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.636      0.872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30     0.693G      2.131          6        224: 100%|██████████| 2368/2368 [07:06<00:00,  5.55it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:44<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.649       0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30     0.693G      2.059          6        224: 100%|██████████| 2368/2368 [07:13<00:00,  5.46it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:43<00:00,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.66      0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30     0.693G      1.989          6        224: 100%|██████████| 2368/2368 [07:04<00:00,  5.58it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:42<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.666      0.891\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      14/30     0.693G      1.935          6        224: 100%|██████████| 2368/2368 [07:19<00:00,  5.39it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:38<00:00,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.672      0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30     0.693G      1.873          6        224: 100%|██████████| 2368/2368 [07:12<00:00,  5.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:41<00:00,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.677      0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30     0.693G      1.825          6        224: 100%|██████████| 2368/2368 [07:11<00:00,  5.49it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:46<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.682      0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30     0.693G      1.768          6        224: 100%|██████████| 2368/2368 [07:08<00:00,  5.52it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:41<00:00,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.687      0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30     0.693G      1.729          6        224: 100%|██████████| 2368/2368 [07:08<00:00,  5.52it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:42<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.69      0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30     0.693G      1.681          6        224: 100%|██████████| 2368/2368 [07:22<00:00,  5.35it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:52<00:00,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.694      0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30     0.693G      1.638          6        224: 100%|██████████| 2368/2368 [07:31<00:00,  5.25it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:50<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.698      0.907\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30     0.693G      1.595          6        224: 100%|██████████| 2368/2368 [07:44<00:00,  5.09it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:44<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.702       0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30     0.693G      1.554          6        224: 100%|██████████| 2368/2368 [07:38<00:00,  5.16it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:48<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.706      0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30     0.693G      1.509          6        224: 100%|██████████| 2368/2368 [07:28<00:00,  5.28it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:45<00:00,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.71      0.914\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      24/30     0.693G      1.466          6        224: 100%|██████████| 2368/2368 [07:24<00:00,  5.33it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:50<00:00,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.715      0.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30     0.693G      1.421          6        224: 100%|██████████| 2368/2368 [07:33<00:00,  5.22it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:52<00:00,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.719      0.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30     0.693G      1.374          6        224: 100%|██████████| 2368/2368 [07:52<00:00,  5.01it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:51<00:00,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.723      0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30     0.693G      1.336          6        224: 100%|██████████| 2368/2368 [07:39<00:00,  5.15it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:49<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.726      0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30     0.693G      1.282          6        224: 100%|██████████| 2368/2368 [07:44<00:00,  5.10it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:52<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.73      0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30     0.693G      1.234          6        224: 100%|██████████| 2368/2368 [07:50<00:00,  5.03it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:00<00:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.735      0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30     0.693G      1.193          6        224: 100%|██████████| 2368/2368 [08:21<00:00,  4.72it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:59<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.739      0.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 4.605 hours.\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_CA2\\weights\\last.pt, 3.4MB\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_CA2\\weights\\best.pt, 3.4MB\n",
      "\n",
      "Validating C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_CA2\\weights\\best.pt...\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "YOLOv8n-cls summary (fused): 33 layers, 1,630,053 parameters, 0 gradients, 3.4 GFLOPs\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:34<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.739      0.927\n",
      "Speed: 0.2ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_CA2\u001B[0m\n",
      "\n",
      "CA model training is complete.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Category 2: Base Model (YOLOv8-cls with neck) + Star Block (Backbone) + Channel",
   "id": "62a30f3d7d1e09cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T10:29:34.291482Z",
     "start_time": "2025-12-19T10:29:33.473814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "ROOT = r\"C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo\"\n",
    "\n",
    "# Use your modified yolov8n-cls.yaml (with neck with Star Block and CA Attention)\n",
    "model_N_star_CA= YOLO(r\"C:/Users/User/PycharmProjects/PythonProject/.venv39/Lib/site-packages/ultralytics/cfg/models/v8/yolov8n-cls.yaml\")"
   ],
   "id": "839ad745a924268",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-cls summary: 106 layers, 2,938,933 parameters, 2,938,933 gradients, 5.9 GFLOPs\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T10:29:47.813489Z",
     "start_time": "2025-12-19T10:29:47.798112Z"
    }
   },
   "cell_type": "code",
   "source": "print(model_N_star_CA.model)",
   "id": "cdad02e1fcf676ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (2): StarBlock(\n",
      "      (proj): Identity()\n",
      "      (dwconv1): ConvBN(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32, bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (f1): ConvBN(\n",
      "        (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (f2): ConvBN(\n",
      "        (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (g): ConvBN(\n",
      "        (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (dwconv2): ConvBN(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32, bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (4): StarBlock(\n",
      "      (proj): Identity()\n",
      "      (dwconv1): ConvBN(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64, bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (f1): ConvBN(\n",
      "        (conv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (f2): ConvBN(\n",
      "        (conv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (g): ConvBN(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (dwconv2): ConvBN(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64, bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (6): StarBlock(\n",
      "      (proj): Identity()\n",
      "      (dwconv1): ConvBN(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (f1): ConvBN(\n",
      "        (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (f2): ConvBN(\n",
      "        (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (g): ConvBN(\n",
      "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (dwconv2): ConvBN(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (8): StarBlock(\n",
      "      (proj): Identity()\n",
      "      (dwconv1): ConvBN(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (f1): ConvBN(\n",
      "        (conv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (f2): ConvBN(\n",
      "        (conv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (g): ConvBN(\n",
      "        (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (dwconv2): ConvBN(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (9): SPPF(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (10): ChannelAttention(\n",
      "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (fc): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (11): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (12): Concat()\n",
      "    (13): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (15): Concat()\n",
      "    (16): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (17): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (18): Concat()\n",
      "    (19): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (20): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (21): Concat()\n",
      "    (22): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (23): Classify(\n",
      "      (conv): Conv(\n",
      "        (conv): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (drop): Dropout(p=0.0, inplace=True)\n",
      "      (linear): Linear(in_features=1280, out_features=101, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T19:45:11.322034Z",
     "start_time": "2025-12-17T14:34:21.419850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_N_star_CA.train(\n",
    "    data=ROOT,\n",
    "    epochs=30,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    device=0,\n",
    "    workers=2,\n",
    "    project=ROOT,\n",
    "    name=\"runs_N_star_CA\",\n",
    ")\n",
    "print(\"\\nCA model with star and neck training is complete.\")\n"
   ],
   "id": "e4b3db4817a71386",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.240 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:/Users/User/PycharmProjects/PythonProject/.venv39/Lib/site-packages/ultralytics/cfg/models/v8/yolov8n-cls.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=runs_N_star_CA, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1     12736  ultralytics.nn.modules.block.StarBlock       [32, 32]                      \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  1     43904  ultralytics.nn.modules.block.StarBlock       [64, 64]                      \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  1    161536  ultralytics.nn.modules.block.StarBlock       [128, 128]                    \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    617984  ultralytics.nn.modules.block.StarBlock       [256, 256]                    \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     65792  ultralytics.nn.modules.conv.ChannelAttention [256]                         \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    156416  ultralytics.nn.modules.block.C2f             [448, 128, 1]                 \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 23                  -1  1    459621  ultralytics.nn.modules.head.Classify         [256, 101]                    \n",
      "YOLOv8n-cls summary: 106 layers, 2,938,933 parameters, 2,938,933 gradients, 5.9 GFLOPs\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 0.70.2 ms, read: 29.96.9 MB/s, size: 48.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 33859 images, 0 corrupt:  45%|████▍     | 33859/75750 [00:29<00:26, 1593.12it/s]C:\\Users\\User\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\PIL\\TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 75750 images, 0 corrupt: 100%|██████████| 75750/75750 [00:55<00:00, 1354.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train.cache\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access  (ping: 0.20.1 ms, read: 54.317.1 MB/s, size: 37.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val...:   0%|          | 0/25250 [00:00<?, ?it/s]C:\\Users\\User\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\PIL\\TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... 25250 images, 0 corrupt: 100%|██████████| 25250/25250 [00:15<00:00, 1606.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val.cache\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01, momentum=0.9) with parameter groups 38 weight(decay=0.0), 48 weight(decay=0.0005), 48 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA\u001B[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30     0.629G      4.605          6        224: 100%|██████████| 2368/2368 [10:53<00:00,  3.62it/s] \n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:50<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0305      0.128\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30     0.775G      4.285          6        224: 100%|██████████| 2368/2368 [09:46<00:00,  4.04it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [03:31<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.115      0.324\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30     0.775G       3.94          6        224: 100%|██████████| 2368/2368 [08:20<00:00,  4.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:46<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.208      0.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30     0.775G      3.575          6        224: 100%|██████████| 2368/2368 [08:00<00:00,  4.92it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:45<00:00,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.307      0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30     0.775G      3.261          6        224: 100%|██████████| 2368/2368 [08:00<00:00,  4.93it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:50<00:00,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.39      0.691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30     0.775G      3.004          6        224: 100%|██████████| 2368/2368 [07:59<00:00,  4.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:43<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.457       0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30     0.775G      2.804          6        224: 100%|██████████| 2368/2368 [07:50<00:00,  5.03it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:42<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.508      0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30     0.775G       2.63          6        224: 100%|██████████| 2368/2368 [08:09<00:00,  4.84it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:48<00:00,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.546      0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30     0.775G       2.49          6        224: 100%|██████████| 2368/2368 [07:50<00:00,  5.04it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:44<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.576      0.838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30     0.775G      2.372          6        224: 100%|██████████| 2368/2368 [08:04<00:00,  4.89it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:47<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.598      0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30     0.775G       2.28          6        224: 100%|██████████| 2368/2368 [08:20<00:00,  4.74it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:55<00:00,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.616      0.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30     0.775G      2.183          6        224: 100%|██████████| 2368/2368 [07:48<00:00,  5.05it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:49<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.629      0.871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30     0.775G      2.107          6        224: 100%|██████████| 2368/2368 [08:03<00:00,  4.90it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:46<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.638      0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30     0.775G      2.041          6        224: 100%|██████████| 2368/2368 [08:03<00:00,  4.90it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:45<00:00,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.645      0.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30     0.775G      1.968          6        224: 100%|██████████| 2368/2368 [07:41<00:00,  5.13it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:46<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.65      0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30     0.775G      1.905          6        224: 100%|██████████| 2368/2368 [07:56<00:00,  4.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:44<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.655      0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30     0.775G      1.852          6        224: 100%|██████████| 2368/2368 [07:59<00:00,  4.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:46<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.66       0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30     0.775G      1.794          6        224: 100%|██████████| 2368/2368 [08:19<00:00,  4.74it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:51<00:00,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.664      0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30     0.775G      1.744          6        224: 100%|██████████| 2368/2368 [07:53<00:00,  5.00it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:49<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.668      0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30     0.775G      1.693          6        224: 100%|██████████| 2368/2368 [08:02<00:00,  4.91it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:05<00:00,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.674      0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30     0.775G       1.64          6        224: 100%|██████████| 2368/2368 [08:45<00:00,  4.50it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:47<00:00,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.678        0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30     0.775G      1.596          6        224: 100%|██████████| 2368/2368 [08:08<00:00,  4.85it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:52<00:00,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.683      0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30     0.775G      1.541          6        224: 100%|██████████| 2368/2368 [08:00<00:00,  4.93it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:50<00:00,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.689      0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30     0.775G      1.492          6        224: 100%|██████████| 2368/2368 [08:18<00:00,  4.75it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:52<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.694      0.907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30     0.775G       1.44          6        224: 100%|██████████| 2368/2368 [08:21<00:00,  4.72it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:55<00:00,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.699      0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30     0.775G      1.386          6        224: 100%|██████████| 2368/2368 [08:03<00:00,  4.90it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:48<00:00,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.703      0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30     0.775G      1.335          6        224: 100%|██████████| 2368/2368 [08:09<00:00,  4.84it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:48<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.708      0.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30     0.775G      1.272          6        224: 100%|██████████| 2368/2368 [08:30<00:00,  4.64it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:52<00:00,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.714      0.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30     0.775G      1.212          6        224: 100%|██████████| 2368/2368 [08:17<00:00,  4.76it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:52<00:00,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.718      0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30     0.775G      1.168          6        224: 100%|██████████| 2368/2368 [09:17<00:00,  4.24it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:06<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.723      0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 5.107 hours.\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA\\weights\\last.pt, 6.0MB\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA\\weights\\best.pt, 6.0MB\n",
      "\n",
      "Validating C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA\\weights\\best.pt...\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "YOLOv8n-cls summary: 80 layers, 2,934,853 parameters, 0 gradients, 5.9 GFLOPs\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:27<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.723      0.921\n",
      "Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA\u001B[0m\n",
      "\n",
      "CA model with star and neck training is complete.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Category 2: Base Model (YOLOv8-cls with neck) + Star Block (Backbone) + Channel (60 epoch)",
   "id": "bae5db702791787d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T14:09:04.965069Z",
     "start_time": "2025-12-20T14:09:02.074774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "ROOT = r\"C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo\"\n",
    "\n",
    "# Use your modified yolov8n-cls.yaml (with neck with CA Attention)\n",
    "model_N_star_CA_60= YOLO(r\"C:/Users/User/PycharmProjects/PythonProject/.venv39/Lib/site-packages/ultralytics/cfg/models/v8/yolov8n-cls.yaml\")"
   ],
   "id": "babacd85afaf527b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-cls summary: 106 layers, 2,938,933 parameters, 2,938,933 gradients, 5.9 GFLOPs\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T14:09:07.788725Z",
     "start_time": "2025-12-20T14:09:07.765388Z"
    }
   },
   "cell_type": "code",
   "source": "print(model_N_star_CA_60)",
   "id": "c6def34e2072b49e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO(\n",
      "  (model): ClassificationModel(\n",
      "    (model): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (2): StarBlock(\n",
      "        (proj): Identity()\n",
      "        (dwconv1): ConvBN(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32, bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (f1): ConvBN(\n",
      "          (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (f2): ConvBN(\n",
      "          (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (g): ConvBN(\n",
      "          (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (dwconv2): ConvBN(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32, bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (act): ReLU6(inplace=True)\n",
      "      )\n",
      "      (3): Conv(\n",
      "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (4): StarBlock(\n",
      "        (proj): Identity()\n",
      "        (dwconv1): ConvBN(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64, bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (f1): ConvBN(\n",
      "          (conv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (f2): ConvBN(\n",
      "          (conv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (g): ConvBN(\n",
      "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (dwconv2): ConvBN(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64, bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (act): ReLU6(inplace=True)\n",
      "      )\n",
      "      (5): Conv(\n",
      "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (6): StarBlock(\n",
      "        (proj): Identity()\n",
      "        (dwconv1): ConvBN(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (f1): ConvBN(\n",
      "          (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (f2): ConvBN(\n",
      "          (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (g): ConvBN(\n",
      "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (dwconv2): ConvBN(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (act): ReLU6(inplace=True)\n",
      "      )\n",
      "      (7): Conv(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (8): StarBlock(\n",
      "        (proj): Identity()\n",
      "        (dwconv1): ConvBN(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (f1): ConvBN(\n",
      "          (conv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (f2): ConvBN(\n",
      "          (conv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (g): ConvBN(\n",
      "          (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (dwconv2): ConvBN(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (act): ReLU6(inplace=True)\n",
      "      )\n",
      "      (9): SPPF(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (10): ChannelAttention(\n",
      "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): Sigmoid()\n",
      "      )\n",
      "      (11): Upsample(scale_factor=2.0, mode='nearest')\n",
      "      (12): Concat()\n",
      "      (13): C2f(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (m): ModuleList(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): Upsample(scale_factor=2.0, mode='nearest')\n",
      "      (15): Concat()\n",
      "      (16): C2f(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (m): ModuleList(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (17): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (18): Concat()\n",
      "      (19): C2f(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (m): ModuleList(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (20): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (21): Concat()\n",
      "      (22): C2f(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (m): ModuleList(\n",
      "          (0): Bottleneck(\n",
      "            (cv1): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "            (cv2): Conv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (23): Classify(\n",
      "        (conv): Conv(\n",
      "          (conv): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (drop): Dropout(p=0.0, inplace=True)\n",
      "        (linear): Linear(in_features=1280, out_features=101, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-20T05:48:20.734614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_N_star_CA_60.train(\n",
    "    data=ROOT,\n",
    "    epochs=60,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    device=0,\n",
    "    workers=4,\n",
    "    project=ROOT,\n",
    "    name=\"runs_N_star_CA_60\",\n",
    ")\n",
    "print(\"\\nCA model (60 epoch) with star and neck training is complete.\")\n"
   ],
   "id": "aa6af1333dcef65f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.240 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=60, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:/Users/User/PycharmProjects/PythonProject/.venv39/Lib/site-packages/ultralytics/cfg/models/v8/yolov8n-cls.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=runs_N_star_CA_60, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_60, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1     12736  ultralytics.nn.modules.block.StarBlock       [32, 32]                      \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  1     43904  ultralytics.nn.modules.block.StarBlock       [64, 64]                      \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  1    161536  ultralytics.nn.modules.block.StarBlock       [128, 128]                    \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    617984  ultralytics.nn.modules.block.StarBlock       [256, 256]                    \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     65792  ultralytics.nn.modules.conv.ChannelAttention [256]                         \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    156416  ultralytics.nn.modules.block.C2f             [448, 128, 1]                 \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 23                  -1  1    459621  ultralytics.nn.modules.head.Classify         [256, 101]                    \n",
      "YOLOv8n-cls summary: 106 layers, 2,938,933 parameters, 2,938,933 gradients, 5.9 GFLOPs\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 0.60.4 ms, read: 48.68.1 MB/s, size: 48.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 75750 images, 0 corrupt: 100%|██████████| 75750/75750 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access  (ping: 0.40.2 ms, read: 37.49.2 MB/s, size: 37.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... 25250 images, 0 corrupt: 100%|██████████| 25250/25250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01, momentum=0.9) with parameter groups 38 weight(decay=0.0), 48 weight(decay=0.0005), 48 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_60\u001B[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/60     0.598G      4.601          6        224: 100%|██████████| 2368/2368 [07:31<00:00,  5.25it/s]\n",
      "               classes   top1_acc   top5_acc:  10%|█         | 41/395 [00:08<00:58,  6.02it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T13:49:11.178192Z",
     "start_time": "2025-12-20T11:19:32.549455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model_N_star_CA_60 = YOLO(r\"C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\Result_CLS_Neck\\runs_N_star_CA_60\\weights\\last.pt\")\n",
    "\n",
    "model_N_star_CA_60.train(\n",
    "    resume=True,  # ✅ resume from where it stopped\n",
    "    device=0\n",
    ")\n"
   ],
   "id": "6e9d980b7b8b0c01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.240 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=60, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_60\\weights\\last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=runs_N_star_CA_60, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, rect=False, resume=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_60\\weights\\last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_60, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1     12736  ultralytics.nn.modules.block.StarBlock       [32, 32]                      \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  1     43904  ultralytics.nn.modules.block.StarBlock       [64, 64]                      \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  1    161536  ultralytics.nn.modules.block.StarBlock       [128, 128]                    \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    617984  ultralytics.nn.modules.block.StarBlock       [256, 256]                    \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     65792  ultralytics.nn.modules.conv.ChannelAttention [256]                         \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    156416  ultralytics.nn.modules.block.C2f             [448, 128, 1]                 \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 23                  -1  1    459621  ultralytics.nn.modules.head.Classify         [256, 101]                    \n",
      "YOLOv8n-cls summary: 106 layers, 2,938,933 parameters, 2,938,933 gradients, 5.9 GFLOPs\n",
      "Transferred 248/248 items from pretrained weights\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 0.40.1 ms, read: 37.211.6 MB/s, size: 48.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 75750 images, 0 corrupt: 100%|██████████| 75750/75750 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access  (ping: 0.30.2 ms, read: 33.84.4 MB/s, size: 37.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... 25250 images, 0 corrupt: 100%|██████████| 25250/25250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01, momentum=0.9) with parameter groups 38 weight(decay=0.0), 48 weight(decay=0.0005), 48 bias(decay=0.0)\n",
      "Resuming training C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_60\\weights\\last.pt from epoch 39 to 60 total epochs\n",
      "Image sizes 224 train, 224 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_60\u001B[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/60      0.57G      1.321          6        224: 100%|██████████| 2368/2368 [11:02<00:00,  3.57it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [03:18<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.744       0.93\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/60     0.744G      1.324          6        224: 100%|██████████| 2368/2368 [05:36<00:00,  7.04it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [00:58<00:00,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.747      0.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/60     0.744G      1.305          6        224: 100%|██████████| 2368/2368 [04:41<00:00,  8.41it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [00:54<00:00,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.75      0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/60     0.744G      1.281          6        224: 100%|██████████| 2368/2368 [04:52<00:00,  8.11it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [00:56<00:00,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.754      0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/60     0.746G      1.263          6        224: 100%|██████████| 2368/2368 [04:53<00:00,  8.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [00:57<00:00,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.758      0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/60     0.746G       1.23          6        224: 100%|██████████| 2368/2368 [04:50<00:00,  8.17it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [00:57<00:00,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.761      0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/60     0.746G      1.199          6        224: 100%|██████████| 2368/2368 [04:46<00:00,  8.27it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [00:58<00:00,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.763      0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/60     0.746G      1.176          6        224: 100%|██████████| 2368/2368 [04:56<00:00,  7.98it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [00:59<00:00,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.766      0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/60     0.746G      1.145          6        224: 100%|██████████| 2368/2368 [05:09<00:00,  7.66it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [00:57<00:00,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.769      0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/60     0.746G      1.124          6        224: 100%|██████████| 2368/2368 [05:09<00:00,  7.65it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [00:57<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.772       0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/60     0.746G      1.079          6        224: 100%|██████████| 2368/2368 [05:49<00:00,  6.78it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:10<00:00,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.774      0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/60     0.746G      1.046          6        224: 100%|██████████| 2368/2368 [05:35<00:00,  7.05it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:09<00:00,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.777      0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      51/60     0.746G      1.023          6        224: 100%|██████████| 2368/2368 [05:36<00:00,  7.04it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:07<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.779      0.944\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      52/60     0.746G     0.9942          6        224: 100%|██████████| 2368/2368 [05:36<00:00,  7.04it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:10<00:00,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.781      0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      53/60     0.746G     0.9507          6        224: 100%|██████████| 2368/2368 [05:27<00:00,  7.23it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:05<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.782      0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      54/60     0.746G     0.9184          6        224: 100%|██████████| 2368/2368 [05:27<00:00,  7.24it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:05<00:00,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.784      0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      55/60     0.746G     0.8799          6        224: 100%|██████████| 2368/2368 [05:23<00:00,  7.33it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:08<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.786      0.947\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      56/60     0.746G     0.8438          6        224: 100%|██████████| 2368/2368 [05:13<00:00,  7.55it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [00:57<00:00,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.788      0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      57/60     0.746G     0.8135          6        224: 100%|██████████| 2368/2368 [05:15<00:00,  7.50it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [00:58<00:00,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.789      0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      58/60     0.746G     0.7817          6        224: 100%|██████████| 2368/2368 [05:39<00:00,  6.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:08<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.79      0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      59/60     0.746G     0.7461          6        224: 100%|██████████| 2368/2368 [05:31<00:00,  7.15it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:10<00:00,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.792      0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      60/60     0.746G     0.7164          6        224: 100%|██████████| 2368/2368 [05:38<00:00,  6.99it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:06<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.794      0.948\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPermissionError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_39140\\1797316263.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mmodel_N_star_CA_60\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mYOLO\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mr\"C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_60\\weights\\last.pt\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m model_N_star_CA_60.train(\n\u001B[0m\u001B[0;32m      6\u001B[0m     \u001B[0mresume\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[1;31m# ✅ resume from where it stopped\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\ultralytics\\engine\\model.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(self, trainer, **kwargs)\u001B[0m\n\u001B[0;32m    795\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    796\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhub_session\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msession\u001B[0m  \u001B[1;31m# attach optional HUB session\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 797\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    798\u001B[0m         \u001B[1;31m# Update model and cfg after training\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    799\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mRANK\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\ultralytics\\engine\\trainer.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    228\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    229\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 230\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_do_train\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mworld_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    231\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    232\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_setup_scheduler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\ultralytics\\engine\\trainer.py\u001B[0m in \u001B[0;36m_do_train\u001B[1;34m(self, world_size)\u001B[0m\n\u001B[0;32m    468\u001B[0m                 \u001B[1;31m# Save model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    469\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mfinal_epoch\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 470\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    471\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_callbacks\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"on_model_save\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    472\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\ultralytics\\engine\\trainer.py\u001B[0m in \u001B[0;36msave_model\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    569\u001B[0m                 \u001B[1;34m\"train_args\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mvars\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[1;31m# save as dict\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    570\u001B[0m                 \u001B[1;34m\"train_metrics\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetrics\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m\"fitness\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfitness\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 571\u001B[1;33m                 \u001B[1;34m\"train_results\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_results_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    572\u001B[0m                 \u001B[1;34m\"date\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mdatetime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misoformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    573\u001B[0m                 \u001B[1;34m\"version\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0m__version__\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\ultralytics\\engine\\trainer.py\u001B[0m in \u001B[0;36mread_results_csv\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    543\u001B[0m         \u001B[1;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mpd\u001B[0m  \u001B[1;31m# scope for faster 'import ultralytics'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    544\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 545\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcsv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0morient\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"list\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    546\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    547\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_model_train\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m   1024\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1025\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1026\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1027\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1028\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    618\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    619\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 620\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    621\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    622\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1618\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1619\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[1;33m|\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1620\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1621\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1622\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1896\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1897\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1898\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1899\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1900\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m     91\u001B[0m             \u001B[1;31m# Fail here loudly instead of in cython after reading\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     92\u001B[0m             \u001B[0mimport_optional_dependency\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"pyarrow\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 93\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reader\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mparsers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTextReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     94\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     95\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munnamed_cols\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munnamed_cols\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.__cinit__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._get_header\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.raise_parser_error\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mPermissionError\u001B[0m: [Errno 13] Permission denied"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T14:22:43.671346Z",
     "start_time": "2025-12-20T14:09:20.575097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model_N_star_CA_60 = YOLO(r\"C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\Result_CLS_Neck\\runs_N_star_CA_60\\weights\\last.pt\")\n",
    "\n",
    "model_N_star_CA_60.train(\n",
    "    resume=True,  # ✅ resume from where it stopped\n",
    "    device=0\n",
    ")\n"
   ],
   "id": "de17b93981899933",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.240 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=60, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_60\\weights\\last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=runs_N_star_CA_60, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, rect=False, resume=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_60\\weights\\last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_60, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1     12736  ultralytics.nn.modules.block.StarBlock       [32, 32]                      \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  1     43904  ultralytics.nn.modules.block.StarBlock       [64, 64]                      \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  1    161536  ultralytics.nn.modules.block.StarBlock       [128, 128]                    \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    617984  ultralytics.nn.modules.block.StarBlock       [256, 256]                    \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     65792  ultralytics.nn.modules.conv.ChannelAttention [256]                         \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    156416  ultralytics.nn.modules.block.C2f             [448, 128, 1]                 \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 23                  -1  1    459621  ultralytics.nn.modules.head.Classify         [256, 101]                    \n",
      "YOLOv8n-cls summary: 106 layers, 2,938,933 parameters, 2,938,933 gradients, 5.9 GFLOPs\n",
      "Transferred 248/248 items from pretrained weights\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 0.90.3 ms, read: 20.55.2 MB/s, size: 48.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 75750 images, 0 corrupt: 100%|██████████| 75750/75750 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access  (ping: 0.40.2 ms, read: 25.56.9 MB/s, size: 37.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... 25250 images, 0 corrupt: 100%|██████████| 25250/25250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01, momentum=0.9) with parameter groups 38 weight(decay=0.0), 48 weight(decay=0.0005), 48 bias(decay=0.0)\n",
      "Resuming training C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_60\\weights\\last.pt from epoch 60 to 60 total epochs\n",
      "Image sizes 224 train, 224 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_60\u001B[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      60/60      0.57G     0.7366          6        224: 100%|██████████| 2368/2368 [08:20<00:00,  4.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:16<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.793      0.949\n",
      "\n",
      "1 epochs completed in 0.164 hours.\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_60\\weights\\last.pt, 6.0MB\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_60\\weights\\best.pt, 6.0MB\n",
      "\n",
      "Validating C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_60\\weights\\best.pt...\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "YOLOv8n-cls summary: 80 layers, 2,934,853 parameters, 0 gradients, 5.9 GFLOPs\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:16<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.793      0.949\n",
      "Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_60\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x00000138041BB940>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.8706930577754974\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.7927128672599792, 'metrics/accuracy_top5': 0.9486732482910156, 'fitness': 0.8706930577754974}\n",
       "save_dir: WindowsPath('C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo/runs_N_star_CA_60')\n",
       "speed: {'preprocess': 0.13729548514856565, 'inference': 0.6535859564356938, 'loss': 0.00043682376242869204, 'postprocess': 0.001650716831703687}\n",
       "task: 'classify'\n",
       "top1: 0.7927128672599792\n",
       "top5: 0.9486732482910156"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Category 2: Base Model (YOLOv8-cls with neck) + Star Block (Backbone) + Spatial",
   "id": "5c0f0df77c392aed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T02:05:50.439249Z",
     "start_time": "2025-12-18T02:05:48.829877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "ROOT = r\"C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo\"\n",
    "\n",
    "# Use your modified yolov8n-cls.yaml (with neck with SA Attention)\n",
    "model_N_star_SA= YOLO(r\"C:/Users/User/PycharmProjects/PythonProject/.venv39/Lib/site-packages/ultralytics/cfg/models/v8/yolov8n-cls.yaml\")"
   ],
   "id": "f2ce53a5cd46a7d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-cls summary: 105 layers, 2,873,239 parameters, 2,873,239 gradients, 5.9 GFLOPs\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T02:05:51.652086Z",
     "start_time": "2025-12-18T02:05:51.636252Z"
    }
   },
   "cell_type": "code",
   "source": "print(model_N_star_SA.model)",
   "id": "73e2985ecd2f01c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (2): StarBlock(\n",
      "      (proj): Identity()\n",
      "      (dwconv1): ConvBN(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32, bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (f1): ConvBN(\n",
      "        (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (f2): ConvBN(\n",
      "        (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (g): ConvBN(\n",
      "        (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (dwconv2): ConvBN(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32, bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (4): StarBlock(\n",
      "      (proj): Identity()\n",
      "      (dwconv1): ConvBN(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64, bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (f1): ConvBN(\n",
      "        (conv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (f2): ConvBN(\n",
      "        (conv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (g): ConvBN(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (dwconv2): ConvBN(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64, bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (6): StarBlock(\n",
      "      (proj): Identity()\n",
      "      (dwconv1): ConvBN(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (f1): ConvBN(\n",
      "        (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (f2): ConvBN(\n",
      "        (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (g): ConvBN(\n",
      "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (dwconv2): ConvBN(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (8): StarBlock(\n",
      "      (proj): Identity()\n",
      "      (dwconv1): ConvBN(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (f1): ConvBN(\n",
      "        (conv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (f2): ConvBN(\n",
      "        (conv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (g): ConvBN(\n",
      "        (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (dwconv2): ConvBN(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (9): SPPF(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (10): SpatialAttention(\n",
      "      (cv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (11): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (12): Concat()\n",
      "    (13): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (15): Concat()\n",
      "    (16): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (17): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (18): Concat()\n",
      "    (19): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (20): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (21): Concat()\n",
      "    (22): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (23): Classify(\n",
      "      (conv): Conv(\n",
      "        (conv): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (drop): Dropout(p=0.0, inplace=True)\n",
      "      (linear): Linear(in_features=1280, out_features=101, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-17T19:48:59.591155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_N_star_SA.train(\n",
    "    data=ROOT,\n",
    "    epochs=30,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    device=0,\n",
    "    workers=2,\n",
    "    project=ROOT,\n",
    "    name=\"runs_N_star_SA\",\n",
    ")\n",
    "print(\"\\nSA model with star and neck training is complete.\")\n"
   ],
   "id": "60f98a060165774d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.240 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:/Users/User/PycharmProjects/PythonProject/.venv39/Lib/site-packages/ultralytics/cfg/models/v8/yolov8n-cls.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=runs_N_star_CA, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1     12736  ultralytics.nn.modules.block.StarBlock       [32, 32]                      \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  1     43904  ultralytics.nn.modules.block.StarBlock       [64, 64]                      \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  1    161536  ultralytics.nn.modules.block.StarBlock       [128, 128]                    \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    617984  ultralytics.nn.modules.block.StarBlock       [256, 256]                    \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1        98  ultralytics.nn.modules.conv.SpatialAttention [7]                           \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    156416  ultralytics.nn.modules.block.C2f             [448, 128, 1]                 \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 23                  -1  1    459621  ultralytics.nn.modules.head.Classify         [256, 101]                    \n",
      "YOLOv8n-cls summary: 105 layers, 2,873,239 parameters, 2,873,239 gradients, 5.9 GFLOPs\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 0.50.1 ms, read: 42.812.9 MB/s, size: 48.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 33800 images, 0 corrupt:  45%|████▍     | 33800/75750 [00:12<00:15, 2716.75it/s]C:\\Users\\User\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\PIL\\TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 75750 images, 0 corrupt: 100%|██████████| 75750/75750 [00:37<00:00, 2030.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train.cache\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access  (ping: 0.10.0 ms, read: 48.813.1 MB/s, size: 37.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val...:   0%|          | 0/25250 [00:00<?, ?it/s]C:\\Users\\User\\PycharmProjects\\PythonProject\\.venv39\\lib\\site-packages\\PIL\\TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... 17341 images, 0 corrupt:  69%|██████▊   | 17341/25250 [00:07<00:04, 1767.90it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T03:25:53.696452Z",
     "start_time": "2025-12-18T02:06:42.251556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model_N_star_SA = YOLO(r\"C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\Result_CLS_Neck\\runs_N_star_SA\\weights\\last.pt\")\n",
    "\n",
    "model_N_star_SA.train(\n",
    "    resume=True,  # ✅ resume from where it stopped\n",
    "    device=0\n",
    ")\n"
   ],
   "id": "a9cdcb991619fdf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.240 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA\\weights\\last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=runs_N_star_CA, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, rect=False, resume=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA\\weights\\last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1     12736  ultralytics.nn.modules.block.StarBlock       [32, 32]                      \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  1     43904  ultralytics.nn.modules.block.StarBlock       [64, 64]                      \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  1    161536  ultralytics.nn.modules.block.StarBlock       [128, 128]                    \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    617984  ultralytics.nn.modules.block.StarBlock       [256, 256]                    \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1        98  ultralytics.nn.modules.conv.SpatialAttention [7]                           \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    156416  ultralytics.nn.modules.block.C2f             [448, 128, 1]                 \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 23                  -1  1    459621  ultralytics.nn.modules.head.Classify         [256, 101]                    \n",
      "YOLOv8n-cls summary: 105 layers, 2,873,239 parameters, 2,873,239 gradients, 5.9 GFLOPs\n",
      "Transferred 247/247 items from pretrained weights\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 0.40.1 ms, read: 42.715.5 MB/s, size: 48.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 75750 images, 0 corrupt: 100%|██████████| 75750/75750 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access  (ping: 0.80.9 ms, read: 14.88.7 MB/s, size: 37.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... 25250 images, 0 corrupt: 100%|██████████| 25250/25250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01, momentum=0.9) with parameter groups 38 weight(decay=0.0), 48 weight(decay=0.0005), 47 bias(decay=0.0)\n",
      "Resuming training C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA\\weights\\last.pt from epoch 26 to 30 total epochs\n",
      "Image sizes 224 train, 224 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA\u001B[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30     0.568G      1.538          6        224: 100%|██████████| 2368/2368 [15:24<00:00,  2.56it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:45<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.697      0.907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30     0.742G      1.485          6        224: 100%|██████████| 2368/2368 [11:41<00:00,  3.38it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:42<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        0.7      0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30     0.744G      1.434          6        224: 100%|██████████| 2368/2368 [11:37<00:00,  3.40it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:47<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.704      0.911\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30     0.744G      1.376          6        224: 100%|██████████| 2368/2368 [11:34<00:00,  3.41it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:33<00:00,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.707      0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30     0.744G      1.336          6        224: 100%|██████████| 2368/2368 [11:12<00:00,  3.52it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:43<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.71      0.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 1.254 hours.\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA\\weights\\last.pt, 5.9MB\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA\\weights\\best.pt, 5.9MB\n",
      "\n",
      "Validating C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA\\weights\\best.pt...\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "YOLOv8n-cls summary: 79 layers, 2,869,159 parameters, 0 gradients, 5.8 GFLOPs\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:38<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.71      0.913\n",
      "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000021CDFB24B20>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.8118019700050354\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.7102574110031128, 'metrics/accuracy_top5': 0.913346529006958, 'fitness': 0.8118019700050354}\n",
       "save_dir: WindowsPath('C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo/runs_N_star_CA')\n",
       "speed: {'preprocess': 0.15337063762331804, 'inference': 1.1956456435644323, 'loss': 0.0016455366330954367, 'postprocess': 0.0010862574253593213}\n",
       "task: 'classify'\n",
       "top1: 0.7102574110031128\n",
       "top5: 0.913346529006958"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Category 2: Base Model (YOLOv8-cls with neck) + Star Block (Backbone) + Channel (100 epoch)",
   "id": "14b442b4c09b5f31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T06:21:27.857703Z",
     "start_time": "2025-12-24T06:21:26.495682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "ROOT = r\"C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo\"\n",
    "\n",
    "# Use your modified yolov8n-cls.yaml (with neck with CA Attention)\n",
    "model_N_star_CA_100= YOLO(r\"C:/Users/User/PycharmProjects/PythonProject/.venv39/Lib/site-packages/ultralytics/cfg/models/v8/yolov8n-cls.yaml\")"
   ],
   "id": "94f2f7483cb35b4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-cls summary: 106 layers, 2,938,933 parameters, 2,938,933 gradients, 5.9 GFLOPs\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T06:21:28.434825Z",
     "start_time": "2025-12-24T06:21:28.423640Z"
    }
   },
   "cell_type": "code",
   "source": "print(model_N_star_CA_100.model)",
   "id": "4b71d8547e5538ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (2): StarBlock(\n",
      "      (proj): Identity()\n",
      "      (dwconv1): ConvBN(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32, bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (f1): ConvBN(\n",
      "        (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (f2): ConvBN(\n",
      "        (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (g): ConvBN(\n",
      "        (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (dwconv2): ConvBN(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32, bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (4): StarBlock(\n",
      "      (proj): Identity()\n",
      "      (dwconv1): ConvBN(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64, bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (f1): ConvBN(\n",
      "        (conv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (f2): ConvBN(\n",
      "        (conv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (g): ConvBN(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (dwconv2): ConvBN(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64, bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (6): StarBlock(\n",
      "      (proj): Identity()\n",
      "      (dwconv1): ConvBN(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (f1): ConvBN(\n",
      "        (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (f2): ConvBN(\n",
      "        (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (g): ConvBN(\n",
      "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (dwconv2): ConvBN(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (8): StarBlock(\n",
      "      (proj): Identity()\n",
      "      (dwconv1): ConvBN(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (f1): ConvBN(\n",
      "        (conv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (f2): ConvBN(\n",
      "        (conv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (g): ConvBN(\n",
      "        (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (dwconv2): ConvBN(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (9): SPPF(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (10): ChannelAttention(\n",
      "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (fc): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (act): Sigmoid()\n",
      "    )\n",
      "    (11): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (12): Concat()\n",
      "    (13): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (15): Concat()\n",
      "    (16): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (17): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (18): Concat()\n",
      "    (19): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (20): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (21): Concat()\n",
      "    (22): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (23): Classify(\n",
      "      (conv): Conv(\n",
      "        (conv): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (drop): Dropout(p=0.0, inplace=True)\n",
      "      (linear): Linear(in_features=1280, out_features=101, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-23T14:37:03.062702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_N_star_CA_100.train(\n",
    "    data=ROOT,\n",
    "    epochs=100,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    device=0,\n",
    "    workers=4,\n",
    "    project=ROOT,\n",
    "    name=\"runs_N_star_CA_100\",\n",
    ")\n",
    "print(\"\\nCA model with star and neck training is completewith 100 epochs.\")\n"
   ],
   "id": "b6d2aded1c6ffc0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.241 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:/Users/User/PycharmProjects/PythonProject/.venv39/Lib/site-packages/ultralytics/cfg/models/v8/yolov8n-cls.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=runs_N_star_CA_100, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_100, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1     12736  ultralytics.nn.modules.block.StarBlock       [32, 32]                      \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  1     43904  ultralytics.nn.modules.block.StarBlock       [64, 64]                      \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  1    161536  ultralytics.nn.modules.block.StarBlock       [128, 128]                    \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    617984  ultralytics.nn.modules.block.StarBlock       [256, 256]                    \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     65792  ultralytics.nn.modules.conv.ChannelAttention [256]                         \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    156416  ultralytics.nn.modules.block.C2f             [448, 128, 1]                 \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 23                  -1  1    459621  ultralytics.nn.modules.head.Classify         [256, 101]                    \n",
      "YOLOv8n-cls summary: 106 layers, 2,938,933 parameters, 2,938,933 gradients, 5.9 GFLOPs\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 0.40.2 ms, read: 59.134.4 MB/s, size: 48.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 75750 images, 0 corrupt: 100%|██████████| 75750/75750 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T11:53:46.060956Z",
     "start_time": "2025-12-24T06:21:32.947938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model_N_star_CA_100 = YOLO(r\"C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\Result_CLS_Neck\\runs_N_star_CA_100\\weights\\last.pt\")\n",
    "\n",
    "model_N_star_CA_100.train(\n",
    "    resume=True,  # ✅ resume from where it stopped\n",
    "    device=0\n",
    ")\n"
   ],
   "id": "ccab3e4b51b3bb76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.241 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_100\\weights\\last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=runs_N_star_CA_100, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo, rect=False, resume=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_100\\weights\\last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_100, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1     12736  ultralytics.nn.modules.block.StarBlock       [32, 32]                      \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  1     43904  ultralytics.nn.modules.block.StarBlock       [64, 64]                      \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  1    161536  ultralytics.nn.modules.block.StarBlock       [128, 128]                    \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    617984  ultralytics.nn.modules.block.StarBlock       [256, 256]                    \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     65792  ultralytics.nn.modules.conv.ChannelAttention [256]                         \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    156416  ultralytics.nn.modules.block.C2f             [448, 128, 1]                 \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 23                  -1  1    459621  ultralytics.nn.modules.head.Classify         [256, 101]                    \n",
      "YOLOv8n-cls summary: 106 layers, 2,938,933 parameters, 2,938,933 gradients, 5.9 GFLOPs\n",
      "Transferred 248/248 items from pretrained weights\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 2.83.0 ms, read: 13.310.5 MB/s, size: 48.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... 75750 images, 0 corrupt: 100%|██████████| 75750/75750 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access  (ping: 1.52.3 ms, read: 9.312.3 MB/s, size: 37.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... 25250 images, 0 corrupt: 100%|██████████| 25250/25250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01, momentum=0.9) with parameter groups 38 weight(decay=0.0), 48 weight(decay=0.0005), 48 bias(decay=0.0)\n",
      "Resuming training C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_100\\weights\\last.pt from epoch 72 to 100 total epochs\n",
      "Image sizes 224 train, 224 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_100\u001B[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      0.57G     0.8514          6        224: 100%|██████████| 2368/2368 [20:25<00:00,  1.93it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [04:22<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.807      0.954\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100     0.744G     0.8795          6        224: 100%|██████████| 2368/2368 [11:38<00:00,  3.39it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [03:15<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.808      0.954\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100     0.744G     0.8771          6        224: 100%|██████████| 2368/2368 [08:42<00:00,  4.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:34<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.81      0.955\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100     0.744G     0.8704          6        224: 100%|██████████| 2368/2368 [10:13<00:00,  3.86it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:24<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.811      0.954\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100     0.746G     0.8591          6        224: 100%|██████████| 2368/2368 [07:40<00:00,  5.14it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:39<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.812      0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100     0.746G     0.8398          6        224: 100%|██████████| 2368/2368 [09:09<00:00,  4.31it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:19<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.812      0.955\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100     0.746G     0.8269          6        224: 100%|██████████| 2368/2368 [08:07<00:00,  4.86it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:11<00:00,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.812      0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100     0.746G     0.8102          6        224: 100%|██████████| 2368/2368 [09:36<00:00,  4.10it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:29<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.813      0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100     0.746G     0.7923          6        224: 100%|██████████| 2368/2368 [10:30<00:00,  3.76it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [03:05<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.813      0.956\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100     0.746G     0.7797          6        224: 100%|██████████| 2368/2368 [10:42<00:00,  3.69it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:51<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.814      0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100     0.746G     0.7507          6        224: 100%|██████████| 2368/2368 [11:43<00:00,  3.37it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [03:03<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.815      0.956\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100     0.746G      0.734          6        224: 100%|██████████| 2368/2368 [10:26<00:00,  3.78it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:42<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.815      0.956\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100     0.746G     0.7214          6        224: 100%|██████████| 2368/2368 [11:52<00:00,  3.32it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [03:16<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.815      0.956\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100     0.746G     0.6937          6        224: 100%|██████████| 2368/2368 [11:30<00:00,  3.43it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [03:05<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.816      0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100     0.746G     0.6661          6        224: 100%|██████████| 2368/2368 [10:08<00:00,  3.89it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:14<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.816      0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100     0.746G     0.6468          6        224: 100%|██████████| 2368/2368 [09:57<00:00,  3.96it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [02:08<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.816      0.955\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100     0.746G     0.6245          6        224: 100%|██████████| 2368/2368 [06:39<00:00,  5.93it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:47<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.816      0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100     0.746G     0.6038          6        224: 100%|██████████| 2368/2368 [06:58<00:00,  5.67it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [03:12<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.816      0.955\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100     0.746G     0.5852          6        224: 100%|██████████| 2368/2368 [12:12<00:00,  3.23it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [03:06<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.816      0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100     0.746G     0.5625          6        224: 100%|██████████| 2368/2368 [05:14<00:00,  7.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:28<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.815      0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100     0.746G     0.5388          6        224: 100%|██████████| 2368/2368 [05:34<00:00,  7.08it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:33<00:00,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.815      0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100     0.746G     0.5169          6        224: 100%|██████████| 2368/2368 [05:21<00:00,  7.36it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:02<00:00,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.813      0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100     0.746G      0.505          6        224: 100%|██████████| 2368/2368 [05:12<00:00,  7.58it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [00:55<00:00,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.813      0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100     0.746G      0.484          6        224: 100%|██████████| 2368/2368 [05:06<00:00,  7.72it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [00:57<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.812      0.955\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100     0.746G     0.4577          6        224: 100%|██████████| 2368/2368 [07:16<00:00,  5.43it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:24<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.813      0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100     0.746G     0.4343          6        224: 100%|██████████| 2368/2368 [05:00<00:00,  7.88it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [00:59<00:00,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.813      0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100     0.746G     0.4241          6        224: 100%|██████████| 2368/2368 [05:58<00:00,  6.60it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:35<00:00,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.813      0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100     0.746G     0.4047          6        224: 100%|██████████| 2368/2368 [06:43<00:00,  5.87it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:30<00:00,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.813      0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100     0.746G     0.3855          6        224: 100%|██████████| 2368/2368 [09:00<00:00,  4.38it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [01:02<00:00,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.812      0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "29 epochs completed in 5.435 hours.\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_100\\weights\\last.pt, 6.0MB\n",
      "Optimizer stripped from C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_100\\weights\\best.pt, 6.0MB\n",
      "\n",
      "Validating C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_100\\weights\\best.pt...\n",
      "Ultralytics 8.3.146  Python-3.9.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "YOLOv8n-cls summary: 80 layers, 2,934,853 parameters, 0 gradients, 5.9 GFLOPs\n",
      "\u001B[34m\u001B[1mtrain:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\train... found 75750 images in 101 classes  \n",
      "\u001B[34m\u001B[1mval:\u001B[0m C:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\val... found 25250 images in 101 classes  \n",
      "\u001B[34m\u001B[1mtest:\u001B[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 395/395 [00:54<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.816      0.956\n",
      "Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001B[1mC:\\Users\\User\\PycharmProjects\\PythonProject\\FYP\\FoodWasteEstimator\\food-101\\food101_yolo\\runs_N_star_CA_100\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000019EE323BDF0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.886000007390976\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.8161584138870239, 'metrics/accuracy_top5': 0.955841600894928, 'fitness': 0.886000007390976}\n",
       "save_dir: WindowsPath('C:/Users/User/PycharmProjects/PythonProject/FYP/FoodWasteEstimator/food-101/food101_yolo/runs_N_star_CA_100')\n",
       "speed: {'preprocess': 0.1439883168334358, 'inference': 1.126944277227348, 'loss': 0.00032372277020822546, 'postprocess': 0.000724788119360611}\n",
       "task: 'classify'\n",
       "top1: 0.8161584138870239\n",
       "top5: 0.955841600894928"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
